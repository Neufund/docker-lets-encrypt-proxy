# Drop privileges
user nobody nobody;

# One worker per core, many connections per worker
worker_processes auto;
events {
	worker_connections  19000;
}
# Each connection needs one filehandle, or two if we miss cache
worker_rlimit_nofile    20000;

http {
	include       mime.types;
	include       headers.conf;
	include       tls-http.conf;
	include       tls-letsencrypt-http.conf;
	include       cache-http.conf;
	include       rate-http.conf;
	default_type  application/octet-stream;
	
	# Logging to standard outputs for docker
	log_format  main  '$time_iso8601 $remote_addr "$request" '
		'$upstream_cache_status $status $request_time $bytes_sent $body_bytes_sent '
		'"$http_referer" "$http_user_agent" "$http_x_forwarded_for"';
	error_log  /dev/stderr;
	access_log /dev/stdout main buffer=4096 flush=1s;
	
	# Compress all content when client supports it. Unfortunately nginx
	# is not smart enough to strore cache content pre-compressed.
	gzip               on;
	gzip_comp_level    1;
	gzip_types         *;
	gzip_proxied       any;
	
	server {
		listen       443 ssl;
		server_name  ${DOMAIN};
		include      tls-server.conf;
		include      tls-letsencrypt-server.conf;
		
		# Reverse proxy
		location / {
			proxy_http_version 1.1;
			proxy_set_header   Host           $host;
			proxy_set_header   X-Real-IP      $remote_addr;
			proxy_pass http://${ORIGIN_HOST}:${ORIGIN_PORT};
		}
	}
	
	server {
		listen       80;
		server_name  ${DOMAIN};
		include      tls-letsencrypt-acme.conf;
		
		# Redirect all traffic to TLS
		location / {
			return 301 https://$server_name$request_uri;
		}
	}
}
